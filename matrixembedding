using LinearAlgebra,Flux,Statistics,TextAnalysis,MLDatasets

#tok=[];

#van=PTBLM(:train)

#for i in 1:length(van.features)
#for j in 1:length(van.features[i])
#push!(tok,van.features[i][j]);
#end;
#push!(tok,".");
#end;

pathname = "C://Users//Joseph Van Name/corpus/thebible.txt";

sd=StringDocument(read(pathname,String));

type=ComplexF64;

remove_corrupt_utf8!(sd);
#prepare!(sd, strip_numbers);
remove_case!(sd);
tok=tokens(sd);
wordlist=unique(tok);
dick=Dict{String,Int64}(wordlist[i]=>i for i=1:length(wordlist))

timelimit=4600;

type=Float64;

wordlist=unique(tok);
dick=Dict{String,Int64}(wordlist[i]=>i for i=1:length(wordlist))

n=length(tok);
r=length(wordlist);
list=Array{Int64}(undef,n);
for i in 1:n
list[i]=dick[tok[i]];
end;

n=length(list);

r=maximum(list);

pp=1;
qq=1;
d=40;
fan=true;

matrixtable=[];
for i in 1:r
push!(matrixtable,randn(type,d,d));
end;

function dumbnorm(x)
return sum(abs.(real.(x))); 
end;

bottomeigenvector=randn(type,d,d)^0;
#bottomeigenvector=(bottomeigenvector+adjoint(bottomeigenvector))/2;
#bottomeigenvector=bottomeigenvector/(norm(bottomeigenvector);

#Um. The manualgradient function does not look right. I need to fix it for the complex case.

function manualgradient(leftvector,rightvector,matrixtable)
leftlist=Array{Matrix{type}}(undef,n+1);
rightlist=Array{Vector{type}}(undef,n+1);
leftscalar=Array{type}(undef,n+1);
rightscalar=Array{type}(undef,n+1);
grad=[];
leftlist[1]=leftvector/norm(leftvector);
rightlist[n+1]=rightvector/norm(rightvector);
leftscalar[1]=0.;
rightscalar[n+1]=0.;
for i in 1:n
dd=leftlist[i]*matrixtable[list[i]];
fdd=dumbnorm(dd);
leftlist[i+1]=dd/fdd;
leftscalar[i+1]=leftscalar[i]+log(fdd);
end;
for i in reverse(1:n)
dd=matrixtable[list[i]]*rightlist[i+1];
fdd=dumbnorm(dd);
rightlist[i]=dd/fdd;
rightscalar[i]=rightscalar[i+1]+log(fdd);
end;

#logeval=log(abs((leftlist[1]*rightlist[1])[1]))+rightscalar[1];

umm=(leftlist[1]*rightlist[1])[1];
logeval=log(abs(umm))+rightscalar[1];

#logeval=log(leftlist[n+1]*rightlist[n+1])+leftscalar[n+1];
for i in 1:r
push!(grad,zeros(d,d));
end;

for i in 1:n
grad[list[i]]=grad[list[i]]+rightlist[i+1]*leftlist[i]*exp(leftscalar[i]+rightscalar[i+1]-logeval);
end;
pan=((leftlist[1]*rightlist[1])[1])/abs((leftlist[1]*rightlist[1])[1]);
#pan=abs((leftlist[1]*rightlist[1])[1])/((leftlist[1]*rightlist[1])[1]);

# The above line may not generalize to complex matrices very well.
#pan=1;
#if (leftlist[1]*rightlist[1])[1]<0
#pan=-1;
#end;

return pan*adjoint.(grad)/n;
end;





function ftopexp(leftvector,rightvector,matrixtable)
testtopeigenvector=deepcopy(leftvector);
for i in 1:n
testtopeigenvector=testtopeigenvector*matrixtable[list[i]];
end;

return log(abs((testtopeigenvector*rightvector)[1]));
end;



function ftop(matrixtable)
testtopeigenvector=deepcopy(topeigenvector);

cc=0;
for i in 1:n
testtopeigenvector=matrixtable[list[i]]*testtopeigenvector;
dd=norm(testtopeigenvector);
testtopeigenvector=testtopeigenvector/dd;
cc=cc+log(dd)/n;
end;

return cc;
end;


function f(matrixtable)
testtopeigenvector=deepcopy(topeigenvector);
testbottomeigenvector=deepcopy(bottomeigenvector);

cc=0;
for i in 1:n
testtopeigenvector=matrixtable[list[i]]*testtopeigenvector;
dd=norm(testtopeigenvector);
testtopeigenvector=testtopeigenvector/dd;
cc=cc+log(dd)/n;
end;

for kk in 1:pp
newtestbottomeigenvector=testbottomeigenvector*0;

for j in 1:r
newtestbottomeigenvector=newtestbottomeigenvector+matrixtable[j]*testbottomeigenvector*adjoint(matrixtable[j]);
end;
testbottomeigenvector=newtestbottomeigenvector;
end;

return cc-log(norm(testbottomeigenvector))/(2*pp);
# Yeah. The cc should be its own function.
# I can even 
end;

function f(leftvector,rightvector,matrixtable)
newleftvector=deepcopy(leftvector);
cc=0;
for i in 1:n
newleftvector=newleftvector*matrixtable[list[i]];
dd=dumbnorm(newleftvector);
cc=cc+log(dd);
newleftvector=newleftvector/dd;
end;
return (cc+log(abs((newleftvector*rightvector)[1])))/n;
end;


function g(matrixtable)
testbottomeigenvector=deepcopy(bottomeigenvector);
for kk in 1:pp
newtestbottomeigenvector=testbottomeigenvector*0;

for j in 1:r
newtestbottomeigenvector=newtestbottomeigenvector+matrixtable[j]*testbottomeigenvector*adjoint(matrixtable[j]);
end;
testbottomeigenvector=newtestbottomeigenvector;
end;
#return log(norm(testbottomeigenvector))/(2*pp);
return log(abs(tr(testbottomeigenvector)))/(2*pp);
end;

function gg(matrixtable)
testbottomeigenvector=zeros(d,d);
for j in 1:r
testbottomeigenvector=testbottomeigenvector+matrixtable[j]*adjoint(matrixtable[j]);
end;
return log(norm(testbottomeigenvector))/2;
end;



function h(leftvector,rightvector,matrixtable)
return f(leftvector,rightvector,matrixtable)-g(matrixtable);
end;

# hh does not rely on the bottomeigenvector


truegrad=function(leftvector,rightvector,matrixtable)
#display(norm(gradient(g,matrixtable)[1]-matrixtable/sum(abs2.(norm.(matrixtable)))));
return manualgradient(leftvector,rightvector,matrixtable)-matrixtable/sum(abs2.(norm.(matrixtable)));
#return manualgradient(leftvector,rightvector,matrixtable)-gradient(g,matrixtable)[1];
end;

rate=10000;
pink=true;
rightvector=randn(type,d);
leftvector=adjoint(randn(type,d));

leftvector=leftvector/norm(leftvector);
rightvector=rightvector/norm(rightvector);

oldtime=time()
	while time()-oldtime<timelimit
       for ami in 1:qq
       newbottomeigenvector=bottomeigenvector*0;
       for j in 1:r
       newbottomeigenvector=newbottomeigenvector+matrixtable[j]*bottomeigenvector*adjoint(matrixtable[j]);
       end;
       bottomeigenvector=(newbottomeigenvector+adjoint(newbottomeigenvector))/(2*norm(newbottomeigenvector));
       bottomeigenvectorroot=sqrt(bottomeigenvector);
       invbottomeigenvectorroot=bottomeigenvectorroot^(-1);
       bottomeigenvector=bottomeigenvector^0;
       for j in 1:r
       matrixtable[j]=invbottomeigenvectorroot*matrixtable[j]*invbottomeigenvectorroot;
       end;
       matrixtable=matrixtable/mean(norm.(matrixtable));
	end;
       grad=truegrad(leftvector,rightvector,matrixtable);
       #grad=gradient(h,leftvector,rightvector,matrixtable)[3];

       # I am saving the old code just in case the calculation is too unstable.
       #old=h(leftvector,rightvector,matrixtable);
       #matrixtable=matrixtable+rate*grad;
       #matrixtable=matrixtable/mean(norm.(matrixtable));
       #new=h(leftvector,rightvector,matrixtable);

       old=h(leftvector,rightvector,matrixtable);
       new=h(leftvector,rightvector,matrixtable+rate*grad);
       if old>=new
       # Here, we decrease the rate until we get something better.
       while true
       rate=rate/2;
       if old<=h(leftvector,rightvector,matrixtable+rate*grad)
       matrixtable=matrixtable+rate*grad;
       matrixtable=matrixtable/mean(norm.(matrixtable));
       display(["minus",old,new,rate]);
       break;
       end;
       end;
       else
       tartable=[[rate,new]];
       while true
       rate=rate*1.4;
       new=h(leftvector,rightvector,matrixtable+rate*grad);
       if last(tartable)[2]<new
       push!(tartable,[rate,new]);
       else
       rate=last(tartable)[1];
       new=last(tartable)[2];
       matrixtable=matrixtable+rate*grad;
       matrixtable=matrixtable/mean(norm.(matrixtable));
       display([old,new,rate]);
       break;
       end;
       end;
       end;

       #tempnew=new;
       #oldrate=rate;
       #newrate=rate*1.4;
       #new=h(leftvector,rightvector,matrixtable+rate*grad);
       #if tempnew>=new
       #rate=oldrate;
       #matrixtable=matrixtable+rate*grad;
       #matrixtable=matrixtable/mean(norm.(matrixtable));
       #display([old,new,rate]);
       #break;
       #end;
       #end;
       end;
