# Here we give examples of graph embeddings constructed using ideas similar to L_{2,d}-spectral radius dimensionality reduction.

# I am going to have to write the code for when the matrix is factored as a product of low rank matrices.

#gradient(g,x,y)[1]-adjoint(u)*adjoint(v)*(u*v)*lambda/abs(u*v*lambda)^2*adjoint(y)

list=[];
type=Float64;
n=30;
nn=Int(n/2);
d=20;
ll=100;
power=2;

list=[];

for i in 1:ll
push!(list,[rand(1:n),rand(1:n)]);
end;

lefteigenvectors=[];
righteigenvectors=[];
for i in 1:ll
push!(lefteigenvectors,adjoint(randn(type,d)));
push!(righteigenvectors,randn(type,d));
end;

#for i in 1:n
#push!(list,[]);
#end;
#for i in 1:n
#for j in 1:(i-1)
#if rand(0:1)==1
#push!(list[i],j);
#push!(list[j],i);
#end;
#end;
#end;

#ll=sum(length.(list));

matscore=function(matrix)
prod=0;
suma=zeros(d,d);
for i in 1:n
suma+=matrix[i]*adjoint(matrix[i]);
for a in list[i]
prod+=log(norm((matrix[a]*matrix[i])^power));
end;
end;
return exp(prod/(ll*2*power))/norm(suma);
end;

slowspedradmatscore=function(matrix)
prod=0;
for i in 1:ll
prod+=abs(rad(matrix[list[i][1]]*matrix[list[i][2]]));
end;
return prod/(2*ll);
end;

specradmatscore=function(matrix)
prod=0;
for i in 1:ll
prod+=abs(dot(righteigenvector[i],matrix[list[i][1]]*matrix[list[i][2]]*righteigenvector[i]));
end;
return prod/(2*ll);
end;



for kk in 1:100
for i in 1:ll
lefteigenvectors[i]=lefteigenvectors[i]*matrixtable[list[i][1]]*matrixtable[list[i][2]];
righteigenvectors[i]=matrixtable[list[i][1]]*matrixtable[list[i][2]]*righteigenvectors[i];
lefteigenvectors[i]=lefteigenvectors[i]/norm(lefteigenvectors[i]);
righteigenvectors[i]=righteigenvectors[i]/norm(righteigenvectors[i]);
end;
end;

gradspecradmatscore=function(lefteigenvectors,righteigenvectors,matrix)
grad=[];
for i in 1:n
push!(grad,zeros(type,d,d));
end;
for i in 1:ll
lambda=dot(righteigenvectors[i],matrix[list[i][1]]*matrix[list[i][2]]*righteigenvectors[i]);
cc=lefteigenvectors[i]*righteigenvectors[i];
grad[list[i][1]]+=adjoint(lefteigenvectors[i])*(adjoint(righteigenvectors[i])*adjoint(matrix[list[i][2]]))*(cc*lambda/abs(cc*lambda)^2);
grad[list[i][2]]+=(adjoint(matrix[list[i][1]])*adjoint(lefteigenvectors[i]))*adjoint(righteigenvectors[i])*(cc*lambda/abs(cc*lambda)^2);
end;

end;


arrayscore=function(leftarray,rightarray)
prod=0;
suma=zeros(d,d);
for i in 1:n
suma+=leftarray[i]*adjoint(leftarray[i])+rightarray[i]*adjoint(rightarray[i]);
for a in list[i]
prod+=log(abs(dot(leftarray[i],rightarray[a])));
end;
end;
return exp(prod/ll)/norm(suma);
end;
qq=0;
rate=.3;

matrixtable=[];
leftarray=[];
rightarray=[];
dr=Int(d/2);
for i in 1:n
xx=randn(type,d,d);
#for j in 1:dr
#for k in 1:dr
#xx[2*j,2*k-1]=-adjoint(xx[2*j-1,2*k]);
#xx[2*j,2*k]=adjoint(xx[2*j-1,2*k-1]);
#end;
#end;

push!(matrixtable,xx);
push!(leftarray,randn(type,d,d));
push!(rightarray,randn(type,d,d));
end;


rate=1;
pp=1;
qq=1;
amm=0;
while true
#  for i in 1:n
#  for j in 1:dr
#  for k in 1:dr
#  matrixtable[i][2*j,2*k-1]=-adjoint(matrixtable[i][2*j-1,2*k]);
#  matrixtable[i][2*j,2*k]=adjoint(matrixtable[i][2*j-1,2*k-1]);
#  end;
#  end;
#  end;

grad=gradient(matscore,matrixtable)[1];
matrixtable=matrixtable+rate*grad;
matrixtable/=mean(norm.(matrixtable));
pp=matscore(matrixtable);
amm=amm*0.99+0.01*(pp-qq);
display([rate,pp,(pp-qq)/amm]);
if qq>pp rate/=2;
end;
rate*=1.01;
qq=pp;
end;


rate=1;
pp=1;
qq=1;
amm=0;
while true
grad=gradient(score,leftarray,rightarray);
leftarray+=rate*grad[1];
rightarray+=rate*grad[2];
amm=norm(leftarray);
leftarray/=amm;
rightarray/=amm;
pp=score(leftarray,rightarray);
amm=amm*0.99+0.01*(pp-qq);
display([rate,pp,(pp-qq)/amm]);
#if qq>pp rate/=2;
#end;
#rate*=1.01;
qq=pp;
end;


